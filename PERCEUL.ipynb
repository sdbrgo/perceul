{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1e6G9G41BAeiZGj1GoxGu91097sPFsusg",
      "authorship_tag": "ABX9TyOs6oddeTYm2YHgpF8DnWEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdbrgo/PERCEUL/blob/main/PERCEUL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "lIgbs-9bAhGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "# pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# preprocesing\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin # used to define NumericSelector(), which is used in preprocessing\n",
        "\n",
        "# dimensionality reduction\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# cluster validation\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# clustering\n",
        "from sklearn.cluster import KMeans, DBSCAN"
      ],
      "metadata": {
        "id": "Hmun0waZAq1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up Hugging Face & Mount GDrive"
      ],
      "metadata": {
        "id": "Azdyovt6i3GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face\n",
        "from huggingface_hub import login\n",
        "login()\n",
        "\n",
        "# mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kAGfM795i2DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "hIaAGxgMAsYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_name = \"\"\n",
        "df = pd.read_csv(ds_name)"
      ],
      "metadata": {
        "id": "rY1VJeKzAxNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "XTN8u1XHAxuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=====================================================================\n",
        "# a custom and dynamic function for selecting numeric columns only.\n",
        "# will be used to make the pipeline\n",
        "class NumericSelector(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.numeric_cols_ = X.select_dtypes(include=[float, int]).columns\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_num = X[self.numeric_cols_]\n",
        "        return X_num\n",
        "#=====================================================================\n",
        "si = SimpleImputer(strategy='median')\n",
        "df_i = si.fit_transform(df)\n",
        "df_i = pd.DataFrame(df_i, columns=df.columns)\n",
        "\n",
        "ss = StandardScaler()\n",
        "df_i_ss = ss.fit_transform(df_i)\n",
        "df_p = pd.DataFrame(df_i_ss, columns=df.columns)"
      ],
      "metadata": {
        "id": "YbYB-pn6A5w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality Reduction 1\n",
        "> The best t-SNE in the iterations should be saved at the end to be used in the pipeline.\n",
        "> Revise loop content to use actual dataset (current is still templated)."
      ],
      "metadata": {
        "id": "6xcgb0kjA-dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=====================================================================\n",
        "# a function that computes for the appropriate perplexity\n",
        "def choose_perplexity(n_features):\n",
        "  if n_features < 10:\n",
        "      return [20, 30, 40]\n",
        "  elif n_features < 30:\n",
        "      return [10, 20, 30]\n",
        "  elif n_features < 100:\n",
        "      return [5, 10, 20]\n",
        "  else:\n",
        "      return [5, 10]\n",
        "#=====================================================================\n",
        "\n",
        "# get number of features from dataset\n",
        "n_features = df_p.shape[1]\n",
        "perplexities = choose_perplexity(n_features)\n",
        "\n",
        "# run t-SNE for each perplexity and plot\n",
        "plt.figure(figsize=(15, 5 * len(perplexities)))\n",
        "\n",
        "for i, p in enumerate(perplexities):\n",
        "    tsne = TSNE(\n",
        "        n_components=2,\n",
        "        perplexity=p,\n",
        "        n_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    df_p_embedded = tsne.fit_transform(df_p)\n",
        "\n",
        "    plt.subplot(len(perplexities), 1, i + 1)\n",
        "    plt.scatter(df_p_embedded[:, 0], df_p_embedded[:, 1], s=8)\n",
        "    plt.title(f\"t-SNE embedding (perplexity = {p})\")\n",
        "    plt.xlabel(\"Component 1\")\n",
        "    plt.ylabel(\"Component 2\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HdqWo-apt6To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cluster Exploration\n"
      ],
      "metadata": {
        "id": "1sj9wcBpBDFj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSQdUZhBBFgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Clustering"
      ],
      "metadata": {
        "id": "hKbh6GTwBF8p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zTV8JaP8BP0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cluster Interpretation"
      ],
      "metadata": {
        "id": "iDj7TmV_BJO2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2iW8ss3DBS46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the PERCEUL Pipeline"
      ],
      "metadata": {
        "id": "mGuCHjjZ6KvI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wEzImQse6OAd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}